## Note

#### off policy methods
+ Markov Walk : with 19 states [left_terminal_reward = 0, right_terminal_reward = 2]
+ at any state node when a target-policy and a off-policy are stochastic then both Pre-instance and Simple Importance sampling method
  both performs equally
+ when a target-policy takes deterministic action in some states Pre-instace method has lower error than Simple Importance sampling method

